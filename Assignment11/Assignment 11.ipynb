{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849dece2",
   "metadata": {},
   "source": [
    "# This is Assignment 11 - Thienkim Le\n",
    "## Requirement 3:\n",
    "In your own words, describe the commonalities and differences between\n",
    "NumPy arrays and Pandas series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f69835",
   "metadata": {},
   "source": [
    "Commonalities:\n",
    "* Both built in Python, providing efficient performance for numerical tasks.\n",
    "* Support indexing and slicing operations for accessing and modifying data.\n",
    "* Allow various mathematical and statistical operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d40815",
   "metadata": {},
   "source": [
    "Differences:\n",
    "\n",
    "* NumPy arrays can have multiple dimensions, while Pandas Series are strictly one-dimensional.\n",
    "* NumPy arrays require homogeneous data types, whereas Pandas Series can accommodate mixed data types.\n",
    "* NumPy arrays use positional integer-based indexing, while Pandas Series allow custom labeled indexes for intuitive access.\n",
    "* Pandas Series offer tailored functionality for data analysis, such as handling missing data and time series.\n",
    "* Pandas Series provide more flexibility with built-in methods for tasks like grouping and filtering.\n",
    "* NumPy arrays are foundational for scientific computing, while Pandas Series are often used alongside DataFrames for comprehensive data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c4b30e",
   "metadata": {},
   "source": [
    "In summary, NumPy arrays excel in numerical computations and multi-dimensional data, while Pandas Series are optimized for labeled one-dimensional data analysis. Choosing between them depends on the specific task requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62aba6e",
   "metadata": {},
   "source": [
    "Below are examples of creating NumPy arrays and Pandas Series, along with some basic operations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95170033",
   "metadata": {},
   "source": [
    "NumPy Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee089de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "NumPy Array - Accessing element at position (1, 2): 6\n",
      "Sum of elements in NumPy array: 15\n",
      "Mean of elements in NumPy array: 3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Creating a NumPy array with multiple dimensions\n",
    "numpy_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(\"NumPy Array:\")\n",
    "print(numpy_array)\n",
    "\n",
    "# NumPy array indexing\n",
    "print(\"NumPy Array - Accessing element at position (1, 2):\", numpy_array[1, 2])\n",
    "\n",
    "# NumPy array for numerical computations\n",
    "numpy_array = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(\"Sum of elements in NumPy array:\", np.sum(numpy_array))\n",
    "print(\"Mean of elements in NumPy array:\", np.mean(numpy_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6869d6a8",
   "metadata": {},
   "source": [
    "Pandas Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbde3c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Series:\n",
      "[1, 'two', 3.0, True]\n",
      "Pandas Series - Accessing element with label 'b': 2\n",
      "Pandas Series with missing data:\n",
      "[1.0, 2.0, nan, 4.0]\n",
      "Pandas Time Series:\n",
      "[1, 2, 3, 4, 5]\n",
      "Grouped Pandas Series:\n",
      "[25, 30]\n",
      "Filtered Pandas Series (values greater than 5):\n",
      "[6, 7, 8, 9, 10]\n",
      "Pandas DataFrame:\n",
      "      Name  Age\n",
      "0    Alice   25\n",
      "1      Bob   30\n",
      "2  Charlie   35\n",
      "Mean age: 30.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a Pandas Series with mixed data types\n",
    "pandas_series = pd.Series([1, 'two', 3.0, True])\n",
    "\n",
    "print(\"Pandas Series:\")\n",
    "print(list(pandas_series))\n",
    "\n",
    "# Pandas Series with custom labeled index\n",
    "pandas_series = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "print(\"Pandas Series - Accessing element with label 'b':\", pandas_series['b'])\n",
    "\n",
    "# Handling missing data in Pandas Series\n",
    "pandas_series_with_missing = pd.Series([1, 2, np.nan, 4])\n",
    "\n",
    "print(\"Pandas Series with missing data:\")\n",
    "print(list(pandas_series_with_missing))\n",
    "\n",
    "# Handling time series data in Pandas Series\n",
    "time_index = pd.date_range('2024-01-01', periods=5)\n",
    "pandas_time_series = pd.Series([1, 2, 3, 4, 5], index=time_index)\n",
    "\n",
    "print(\"Pandas Time Series:\")\n",
    "print(list(pandas_time_series))\n",
    "\n",
    "# Grouping data in Pandas Series\n",
    "pandas_series_grouped = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "grouped = pandas_series_grouped.groupby(lambda x: 'Even' if x % 2 == 0 else 'Odd').sum()\n",
    "\n",
    "print(\"Grouped Pandas Series:\")\n",
    "print(list(grouped))\n",
    "\n",
    "# Filtering data in Pandas Series\n",
    "filtered_series = pandas_series_grouped[pandas_series_grouped > 5]\n",
    "\n",
    "print(\"Filtered Pandas Series (values greater than 5):\")\n",
    "print(list(filtered_series))\n",
    "\n",
    "# Creating a Pandas DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Pandas DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Performing data analysis with Pandas DataFrame\n",
    "print(\"Mean age:\", df['Age'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d5b422",
   "metadata": {},
   "source": [
    "## Requirement 4\n",
    "Create a Pandas series named bill_names with American currency bill\n",
    "denominations as indices (keys) and President last names as values. For\n",
    "example: 1 – Washington, 2 – Jefferson, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf6893bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Series - bill_names:\n",
      "['Washington', 'Jefferson', 'Lincoln', 'Hamilton', 'Jackson', 'Grant', 'Franklin']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with American currency bill denominations as keys and President last names as values\n",
    "bill_names_data = {\n",
    "    1: 'Washington',\n",
    "    2: 'Jefferson',\n",
    "    5: 'Lincoln',\n",
    "    10: 'Hamilton',\n",
    "    20: 'Jackson',\n",
    "    50: 'Grant',\n",
    "    100: 'Franklin'\n",
    "}\n",
    "\n",
    "# Create the Pandas Series\n",
    "bill_names = pd.Series(bill_names_data)\n",
    "\n",
    "# Print the Pandas Series\n",
    "print(\"Pandas Series - bill_names:\")\n",
    "print(list(bill_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c2e109",
   "metadata": {},
   "source": [
    "## Requirement 5\n",
    "Create a Pandas series-as-dictionary beverages_dict. Make the indices\n",
    "beverage names and comments about the beverage as values. For example:\n",
    "‘Aquafina’: ‘This is my favorite bottled water!’. Demonstrate accessing:\n",
    "* individual values via the keys\n",
    "* multiple values via slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07762373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment about Aquafina: This is my favorite bottled water!\n",
      "Comment about Coffee: Helps me wake up in the morning.\n",
      "\n",
      "Comments about the first three beverages:\n",
      "Aquafina        This is my favorite bottled water!\n",
      "Coca-Cola    Classic soda with a refreshing taste.\n",
      "Coffee            Helps me wake up in the morning.\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with beverage names as keys and comments as values\n",
    "beverages_data = {\n",
    "    'Aquafina': 'This is my favorite bottled water!',\n",
    "    'Coca-Cola': 'Classic soda with a refreshing taste.',\n",
    "    'Coffee': 'Helps me wake up in the morning.',\n",
    "    'Orange Juice': 'Freshly squeezed orange juice is the best!',\n",
    "    'Green Tea': 'A calming and healthy beverage option.',\n",
    "    'Milk': 'Great source of calcium for strong bones.'\n",
    "}\n",
    "\n",
    "# Create the Pandas Series\n",
    "beverages_dict = pd.Series(beverages_data)\n",
    "\n",
    "# Accessing individual values via keys\n",
    "print(\"Comment about Aquafina:\", beverages_dict['Aquafina'])\n",
    "print(\"Comment about Coffee:\", beverages_dict['Coffee'])\n",
    "\n",
    "# Accessing multiple values via slicing\n",
    "print(\"\\nComments about the first three beverages:\")\n",
    "print(beverages_dict[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d243e34c",
   "metadata": {},
   "source": [
    "## Requirement 6\n",
    "Obtain the real city proper population data for the following cities:\n",
    "Chongquing, Shanghai, Tokyo, Moscow, Mexico City, London, & New York.\n",
    "Create a series-as-dictionary named population based on this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a5edab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population Series:\n",
      "Chongqing      30000000\n",
      "Shanghai       27000000\n",
      "Tokyo          38000000\n",
      "Moscow         12000000\n",
      "Mexico City    21000000\n",
      "London          9000000\n",
      "New York       20000000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with city names as keys and population as values\n",
    "population_data = {\n",
    "    'Chongqing': 30000000,\n",
    "    'Shanghai': 27000000,\n",
    "    'Tokyo': 38000000,\n",
    "    'Moscow': 12000000,\n",
    "    'Mexico City': 21000000,\n",
    "    'London': 9000000,\n",
    "    'New York': 20000000\n",
    "}\n",
    "\n",
    "# Create the Pandas Series\n",
    "population = pd.Series(population_data)\n",
    "\n",
    "# Print the Pandas Series\n",
    "print(\"Population Series:\")\n",
    "print(population)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ddcbeb",
   "metadata": {},
   "source": [
    "## Requirement 7\n",
    "Create a Pandas series-as-dictionary named city_country with the cities in\n",
    "population and the countries for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a965c281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City-Country Series:\n",
      "Chongqing               China\n",
      "Shanghai                China\n",
      "Tokyo                   Japan\n",
      "Moscow                 Russia\n",
      "Mexico City            Mexico\n",
      "London         United Kingdom\n",
      "New York        United States\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary containing city-country mappings\n",
    "city_country_data = {\n",
    "    'Chongqing': 'China',\n",
    "    'Shanghai': 'China',\n",
    "    'Tokyo': 'Japan',\n",
    "    'Moscow': 'Russia',\n",
    "    'Mexico City': 'Mexico',\n",
    "    'London': 'United Kingdom',\n",
    "    'New York': 'United States'\n",
    "}\n",
    "\n",
    "# Create the Pandas Series\n",
    "city_country = pd.Series(city_country_data)\n",
    "\n",
    "# Print the Pandas Series\n",
    "print(\"City-Country Series:\")\n",
    "print(city_country)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a2419",
   "metadata": {},
   "source": [
    "## Requirement 8\n",
    "Create a Pandas dataframe object named city_dataframe from a dictionary\n",
    "of series objects using population and city_country. Show:\n",
    "* the .index property\n",
    "* the .columns property\n",
    "* the .keys() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba83a683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the DataFrame:\n",
      "['Chongqing', 'Shanghai', 'Tokyo', 'Moscow', 'Mexico City', 'London', 'New York']\n",
      "\n",
      "Columns of the DataFrame:\n",
      "['Population', 'Country']\n",
      "\n",
      "Keys of the DataFrame:\n",
      "['Population', 'Country']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary of Series objects\n",
    "data = {\n",
    "    'Population': population,\n",
    "    'Country': city_country\n",
    "}\n",
    "\n",
    "# Create the Pandas DataFrame\n",
    "city_dataframe = pd.DataFrame(data)\n",
    "\n",
    "# Show the .index property\n",
    "print(\"Index of the DataFrame:\")\n",
    "print(list(city_dataframe.index))\n",
    "\n",
    "# Show the .columns property\n",
    "print(\"\\nColumns of the DataFrame:\")\n",
    "print(list(city_dataframe.columns))\n",
    "\n",
    "# Show the .keys() method\n",
    "print(\"\\nKeys of the DataFrame:\")\n",
    "print(list(city_dataframe.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352b663",
   "metadata": {},
   "source": [
    "## Requirement 9\n",
    "Create a Pandas series object named my_pd_series from a collection of\n",
    "string keys and collection of numeric values of your choosing. Demonstrate:\n",
    "* modifying a value based on key\n",
    "* slicing by explicit index\n",
    "* slicing by implicit integer index\n",
    "* masking\n",
    "* fancy indexing\n",
    "* loc[]\n",
    "* iloc[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd3bf08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing by explicit index:\n",
      "B    20\n",
      "C    35\n",
      "D    40\n",
      "dtype: int64\n",
      "\n",
      "Slicing by implicit integer index:\n",
      "B    20\n",
      "C    35\n",
      "dtype: int64\n",
      "\n",
      "Masking:\n",
      "C    35\n",
      "D    40\n",
      "E    50\n",
      "dtype: int64\n",
      "\n",
      "Fancy indexing:\n",
      "A    10\n",
      "C    35\n",
      "E    50\n",
      "dtype: int64\n",
      "\n",
      "Using loc[]:\n",
      "20\n",
      "\n",
      "Using iloc[]:\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a Pandas Series\n",
    "keys = ['A', 'B', 'C', 'D', 'E']\n",
    "values = [10, 20, 30, 40, 50]\n",
    "my_pd_series = pd.Series(values, index=keys)\n",
    "\n",
    "# Modify a value based on key\n",
    "my_pd_series['C'] = 35\n",
    "\n",
    "# Slicing by explicit index\n",
    "print(\"Slicing by explicit index:\")\n",
    "print(my_pd_series['B':'D'])  # Slicing from 'B' to 'D', inclusive\n",
    "\n",
    "# Slicing by implicit integer index\n",
    "print(\"\\nSlicing by implicit integer index:\")\n",
    "print(my_pd_series[1:3])  # Slicing from index 1 to 2, excluding 3\n",
    "\n",
    "# Masking\n",
    "print(\"\\nMasking:\")\n",
    "print(my_pd_series[my_pd_series > 30])  # Selecting values greater than 30\n",
    "\n",
    "# Fancy indexing\n",
    "print(\"\\nFancy indexing:\")\n",
    "print(my_pd_series[['A', 'C', 'E']])  # Selecting values with keys 'A', 'C', and 'E'\n",
    "\n",
    "# Using loc[]\n",
    "print(\"\\nUsing loc[]:\")\n",
    "print(my_pd_series.loc['B'])  # Accessing value using label 'B'\n",
    "\n",
    "# Using iloc[]\n",
    "print(\"\\nUsing iloc[]:\")\n",
    "print(my_pd_series.iloc[3])  # Accessing value using integer index 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7245d0e4",
   "metadata": {},
   "source": [
    "## Requirment 10\n",
    "Using city_dataframe, demonstrate:\n",
    "* access column via dictionary-style indexing of the column name\n",
    "* access column via column names that are strings\n",
    "* add a new column to the city_dataframe named altitude. Hint: See\n",
    "this example for adding columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7bd9fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>423967</td>\n",
       "      <td>38332521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>695662</td>\n",
       "      <td>26448193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>141297</td>\n",
       "      <td>19651127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>170312</td>\n",
       "      <td>19552860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>149995</td>\n",
       "      <td>12882135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area       pop\n",
       "California  423967  38332521\n",
       "Texas       695662  26448193\n",
       "New York    141297  19651127\n",
       "Florida     170312  19552860\n",
       "Illinois    149995  12882135"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area = pd.Series({'California': 423967, 'Texas': 695662,\n",
    "                   'New York': 141297, 'Florida': 170312,\n",
    "                   'Illinois': 149995})\n",
    "\n",
    "pop = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
    "                 'New York': 19651127, 'Florida': 19552860,\n",
    "                 'Illinois': 12882135})\n",
    "\n",
    "data = pd.DataFrame({'area': area, 'pop': pop})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b807889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access column 'area' via dictionary-style indexing:\n",
      "California    423967\n",
      "Texas         695662\n",
      "New York      141297\n",
      "Florida       170312\n",
      "Illinois      149995\n",
      "Name: area, dtype: int64\n",
      "\n",
      "Access column 'pop' via column names as strings:\n",
      "<bound method DataFrame.pop of               area       pop  altitude\n",
      "California  423967  38332521      1000\n",
      "Texas       695662  26448193       500\n",
      "New York    141297  19651127       200\n",
      "Florida     170312  19552860        50\n",
      "Illinois    149995  12882135       300>\n",
      "\n",
      "DataFrame with new column 'altitude':\n",
      "              area       pop  altitude\n",
      "California  423967  38332521       100\n",
      "Texas       695662  26448193       200\n",
      "New York    141297  19651127        50\n",
      "Florida     170312  19552860       150\n",
      "Illinois    149995  12882135        75\n"
     ]
    }
   ],
   "source": [
    "# Access column via dictionary-style indexing of the column name\n",
    "area_column = data['area']\n",
    "print(\"Access column 'area' via dictionary-style indexing:\")\n",
    "print(area_column)\n",
    "\n",
    "# Access column via column names that are strings\n",
    "pop_column = data.pop\n",
    "print(\"\\nAccess column 'pop' via column names as strings:\")\n",
    "print(pop_column)\n",
    "\n",
    "# Add a new column to the city_dataframe named 'altitude'\n",
    "altitude_data = pd.Series({'California': 100, 'Texas': 200, 'New York': 50, 'Florida': 150, 'Illinois': 75})\n",
    "data['altitude'] = altitude_data\n",
    "\n",
    "print(\"\\nDataFrame with new column 'altitude':\")\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e978d410",
   "metadata": {},
   "source": [
    "## Requirement 11\n",
    "Create two Pandas series that when added using ‘+’ produce some NaN\n",
    "entries. Use the .add() method and a fill_value to replace the NaN entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2b2693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of addition with NaN entries:\n",
      "a     NaN\n",
      "b     7.0\n",
      "c     9.0\n",
      "d    11.0\n",
      "dtype: float64\n",
      "\n",
      "Filled result using .add() with fill_value:\n",
      "a     1.0\n",
      "b     7.0\n",
      "c     9.0\n",
      "d    11.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the first Pandas Series\n",
    "series1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Create the second Pandas Series\n",
    "series2 = pd.Series([5, 6, 7], index=['b', 'c', 'd'])\n",
    "\n",
    "# Add the two series using the '+' operator\n",
    "result = series1 + series2\n",
    "\n",
    "print(\"Result of addition with NaN entries:\")\n",
    "print(result)\n",
    "\n",
    "# Use the .add() method with fill_value to replace NaN entries\n",
    "filled_result = series1.add(series2, fill_value=0)\n",
    "\n",
    "print(\"\\nFilled result using .add() with fill_value:\")\n",
    "print(filled_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a00b57",
   "metadata": {},
   "source": [
    "## Requirement 12\n",
    "Create two Pandas dataframes that when added using ‘+’ produce some\n",
    "NaN entries. Use the .add() method and a fill_value of the mean of one of\n",
    "the dataframes to replace the NaN entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf5d9313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of addition with NaN entries:\n",
      "    A     B   C\n",
      "W NaN   NaN NaN\n",
      "X NaN   NaN NaN\n",
      "Y NaN  12.0 NaN\n",
      "Z NaN  14.0 NaN\n",
      "\n",
      "Filled df2 with mean of df1:\n",
      "   B   C\n",
      "Y  7  10\n",
      "Z  8  11\n",
      "W  9  12\n",
      "\n",
      "Filled result using .add() with fill_value as the mean of df1:\n",
      "     A     B     C\n",
      "W  NaN   9.0  12.0\n",
      "X  1.0   4.0   NaN\n",
      "Y  2.0  12.0  10.0\n",
      "Z  3.0  14.0  11.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the first Pandas DataFrame\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}, index=['X', 'Y', 'Z'])\n",
    "\n",
    "# Create the second Pandas DataFrame\n",
    "df2 = pd.DataFrame({'B': [7, 8, 9], 'C': [10, 11, 12]}, index=['Y', 'Z', 'W'])\n",
    "\n",
    "# Add the two DataFrames using the '+' operator\n",
    "result = df1 + df2\n",
    "\n",
    "print(\"Result of addition with NaN entries:\")\n",
    "print(result)\n",
    "\n",
    "# Calculate the mean of df1\n",
    "mean_df1 = df1.mean()\n",
    "\n",
    "# Fill NaN values in df2 with the mean of df1\n",
    "filled_df2 = df2.fillna(mean_df1)\n",
    "\n",
    "print(\"\\nFilled df2 with mean of df1:\")\n",
    "print(filled_df2)\n",
    "\n",
    "# Add df1 and filled_df2\n",
    "filled_result = df1.add(filled_df2, fill_value=0)\n",
    "\n",
    "print(\"\\nFilled result using .add() with fill_value as the mean of df1:\")\n",
    "print(filled_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d713c90",
   "metadata": {},
   "source": [
    "## Requirement 13\n",
    "Create a two-dimensional NumPy array using:\n",
    "* A = rng.randint(5, 10, size=(4, 4))\n",
    "* Demonstrate: subtracting row 0 of A from A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a66dd985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array A:\n",
      "[[8 6 7 8]\n",
      " [6 5 6 9]\n",
      " [7 9 5 8]\n",
      " [8 5 6 9]]\n",
      "\n",
      "Result after subtracting row 0 of A from A:\n",
      "[[ 0  0  0  0]\n",
      " [-2 -1 -1  1]\n",
      " [-1  3 -2  0]\n",
      " [ 0 -1 -1  1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a random number generator\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# Create a 4x4 NumPy array with random integers between 5 and 10\n",
    "A = rng.integers(5, 10, size=(4, 4))\n",
    "\n",
    "# Display the original array A\n",
    "print(\"Original Array A:\")\n",
    "print(A)\n",
    "\n",
    "# Subtract row 0 of A from A\n",
    "result = A - A[0]\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nResult after subtracting row 0 of A from A:\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a284d6b",
   "metadata": {},
   "source": [
    "## Requirement 14\n",
    "Create a Pandas dataframe using:\n",
    "* df = pd.DataFrame(A, columns=list('QRST'))\n",
    "* Demonstrate: subtracting row 1 of df from df using df.iloc[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c14adb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df:\n",
      "   Q  R  S  T\n",
      "0  5  6  7  8\n",
      "1  9  7  6  5\n",
      "2  8  9  6  7\n",
      "3  5  6  7  8\n",
      "\n",
      "Result after subtracting row 1 of df from df:\n",
      "   Q  R  S  T\n",
      "0 -4 -1  1  3\n",
      "1  0  0  0  0\n",
      "2 -1  2  0  2\n",
      "3 -4 -1  1  3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming A is already defined as a NumPy array\n",
    "A = np.array([[5, 6, 7, 8],\n",
    "              [9, 7, 6, 5],\n",
    "              [8, 9, 6, 7],\n",
    "              [5, 6, 7, 8]])\n",
    "\n",
    "# Create a Pandas DataFrame using the NumPy array A\n",
    "df = pd.DataFrame(A, columns=list('QRST'))\n",
    "\n",
    "# Display the DataFrame df\n",
    "print(\"DataFrame df:\")\n",
    "print(df)\n",
    "\n",
    "# Subtract row 1 of df from df itself\n",
    "result = df - df.iloc[1]\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nResult after subtracting row 1 of df from df:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a9d98",
   "metadata": {},
   "source": [
    "## Requirement 15\n",
    "Compare and contrast the two sentinel values Pandas uses to represent\n",
    "missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d80fae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in the Series:\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "5    False\n",
      "dtype: bool\n",
      "\n",
      "Series with NaN values filled with 0:\n",
      "0    1.0\n",
      "1    2.0\n",
      "2    0.0\n",
      "3    4.0\n",
      "4    0.0\n",
      "5    6.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a Pandas Series with NaN values\n",
    "data = [1, 2, np.nan, 4, np.nan, 6]\n",
    "series_with_nan = pd.Series(data)\n",
    "\n",
    "# Checking for NaN values\n",
    "print(\"NaN values in the Series:\")\n",
    "print(series_with_nan.isna())\n",
    "\n",
    "# Filling NaN values with a specific value\n",
    "filled_series = series_with_nan.fillna(0)\n",
    "print(\"\\nSeries with NaN values filled with 0:\")\n",
    "print(filled_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbb21c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None values in the DataFrame:\n",
      "       A      B\n",
      "0  False   True\n",
      "1  False  False\n",
      "2   True  False\n",
      "3  False   True\n",
      "4   True  False\n",
      "\n",
      "DataFrame with None values filled with 0:\n",
      "     A    B\n",
      "0  1.0  0.0\n",
      "1  2.0  5.0\n",
      "2  0.0  6.0\n",
      "3  4.0  0.0\n",
      "4  0.0  8.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a Pandas DataFrame with None values\n",
    "data = {'A': [1, 2, None, 4, None],\n",
    "        'B': [None, 5, 6, None, 8]}\n",
    "df_with_none = pd.DataFrame(data)\n",
    "\n",
    "# Checking for None values\n",
    "print(\"None values in the DataFrame:\")\n",
    "print(df_with_none.isna())\n",
    "\n",
    "# Filling None values with a specific value\n",
    "filled_df = df_with_none.fillna(0)\n",
    "print(\"\\nDataFrame with None values filled with 0:\")\n",
    "print(filled_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb790f0a",
   "metadata": {},
   "source": [
    "## Requirement 16\n",
    "Demonstrate the %timeit difference between operations using Python\n",
    "objects and Python integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e41cfb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 ns ± 1.74 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n",
      "8.32 ns ± 0.532 ns per loop (mean ± std. dev. of 7 runs, 100,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Define two Python objects\n",
    "obj1 = object()\n",
    "obj2 = object()\n",
    "\n",
    "# Define two Python integers\n",
    "int1 = 10\n",
    "int2 = 20\n",
    "\n",
    "# Time the creation of Python objects\n",
    "%timeit object()\n",
    "\n",
    "# Time the creation of Python integers\n",
    "%timeit 10 + 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab49c3",
   "metadata": {},
   "source": [
    "## Requirement 17\n",
    "Create a Pandas series containing null data. Use .isnull() to identify the\n",
    "entries that are null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90d6aff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Series:\n",
      "0    1.0\n",
      "1    NaN\n",
      "2    3.0\n",
      "3    NaN\n",
      "4    5.0\n",
      "dtype: float64\n",
      "\n",
      "Null Entries:\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a Pandas Series with null data\n",
    "data = [1, None, 3, None, 5]\n",
    "series_with_null = pd.Series(data)\n",
    "\n",
    "# Identify the null entries using .isnull()\n",
    "null_entries = series_with_null.isnull()\n",
    "\n",
    "# Display the original series\n",
    "print(\"Original Series:\")\n",
    "print(series_with_null)\n",
    "\n",
    "# Display the null entries\n",
    "print(\"\\nNull Entries:\")\n",
    "print(null_entries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6776a5f4",
   "metadata": {},
   "source": [
    "## Requirement 18\n",
    "Create a Pandas dataframe containing null values. Demonstrate:\n",
    "* drop all rows containing a null value\n",
    "* drop all columns containing a null value\n",
    "* drop only rows that contain all null values\n",
    "* drop only columns that contain all null values\n",
    "* replacing null with 0\n",
    "* forward fill\n",
    "* backward fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d02bd0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     A    B     C\n",
      "0  1.0  NaN  10.0\n",
      "1  2.0  6.0  11.0\n",
      "2  NaN  7.0  12.0\n",
      "3  4.0  NaN  13.0\n",
      "4  5.0  9.0   NaN\n",
      "\n",
      "DataFrame after dropping rows containing a null value:\n",
      "     A    B     C\n",
      "1  2.0  6.0  11.0\n",
      "\n",
      "DataFrame after dropping columns containing a null value:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4]\n",
      "\n",
      "DataFrame after dropping only rows that contain all null values:\n",
      "     A    B     C\n",
      "0  1.0  NaN  10.0\n",
      "1  2.0  6.0  11.0\n",
      "2  NaN  7.0  12.0\n",
      "3  4.0  NaN  13.0\n",
      "4  5.0  9.0   NaN\n",
      "\n",
      "DataFrame after dropping only columns that contain all null values:\n",
      "     A    B     C\n",
      "0  1.0  NaN  10.0\n",
      "1  2.0  6.0  11.0\n",
      "2  NaN  7.0  12.0\n",
      "3  4.0  NaN  13.0\n",
      "4  5.0  9.0   NaN\n",
      "\n",
      "DataFrame after replacing null values with 0:\n",
      "     A    B     C\n",
      "0  1.0  0.0  10.0\n",
      "1  2.0  6.0  11.0\n",
      "2  0.0  7.0  12.0\n",
      "3  4.0  0.0  13.0\n",
      "4  5.0  9.0   0.0\n",
      "\n",
      "DataFrame after forward filling null values:\n",
      "     A    B     C\n",
      "0  1.0  NaN  10.0\n",
      "1  2.0  6.0  11.0\n",
      "2  2.0  7.0  12.0\n",
      "3  4.0  7.0  13.0\n",
      "4  5.0  9.0  13.0\n",
      "\n",
      "DataFrame after backward filling null values:\n",
      "     A    B     C\n",
      "0  1.0  6.0  10.0\n",
      "1  2.0  6.0  11.0\n",
      "2  4.0  7.0  12.0\n",
      "3  4.0  9.0  13.0\n",
      "4  5.0  9.0   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a Pandas DataFrame with null values\n",
    "data = {\n",
    "    'A': [1, 2, None, 4, 5],\n",
    "    'B': [None, 6, 7, None, 9],\n",
    "    'C': [10, 11, 12, 13, None]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop all rows containing a null value\n",
    "df_drop_rows = df.dropna()\n",
    "\n",
    "# Drop all columns containing a null value\n",
    "df_drop_columns = df.dropna(axis=1)\n",
    "\n",
    "# Drop only rows that contain all null values\n",
    "df_drop_rows_all_null = df.dropna(how='all')\n",
    "\n",
    "# Drop only columns that contain all null values\n",
    "df_drop_columns_all_null = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Replace null values with 0\n",
    "df_replace_null_with_zero = df.fillna(0)\n",
    "\n",
    "# Forward fill null values\n",
    "df_forward_fill = df.fillna(method='ffill')\n",
    "\n",
    "# Backward fill null values\n",
    "df_backward_fill = df.fillna(method='bfill')\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Display the DataFrame after each operation\n",
    "print(\"\\nDataFrame after dropping rows containing a null value:\")\n",
    "print(df_drop_rows)\n",
    "\n",
    "print(\"\\nDataFrame after dropping columns containing a null value:\")\n",
    "print(df_drop_columns)\n",
    "\n",
    "print(\"\\nDataFrame after dropping only rows that contain all null values:\")\n",
    "print(df_drop_rows_all_null)\n",
    "\n",
    "print(\"\\nDataFrame after dropping only columns that contain all null values:\")\n",
    "print(df_drop_columns_all_null)\n",
    "\n",
    "print(\"\\nDataFrame after replacing null values with 0:\")\n",
    "print(df_replace_null_with_zero)\n",
    "\n",
    "print(\"\\nDataFrame after forward filling null values:\")\n",
    "print(df_forward_fill)\n",
    "\n",
    "print(\"\\nDataFrame after backward filling null values:\")\n",
    "print(df_backward_fill)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b1b546",
   "metadata": {},
   "source": [
    "## Requirement 19\n",
    "Demonstrate Pandas MultiIndex techniques (can use book examples):\n",
    "* .from_tuples()\n",
    "* .reindex()\n",
    "* .unstack()\n",
    "* .stack()\n",
    "* indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e94c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Series:\n",
      "Letter  Number\n",
      "A       1         10\n",
      "        2         20\n",
      "B       1         30\n",
      "        2         40\n",
      "dtype: int64\n",
      "\n",
      "Reindexed Series:\n",
      "Letter  Number  Subgroup\n",
      "A       1       X           10.0\n",
      "                Y           10.0\n",
      "B       2       X           40.0\n",
      "C       1       Y            NaN\n",
      "dtype: float64\n",
      "\n",
      "Unstacked DataFrame:\n",
      "Number   1   2\n",
      "Letter        \n",
      "A       10  20\n",
      "B       30  40\n",
      "\n",
      "Stacked Series:\n",
      "Letter  Number\n",
      "A       1         10\n",
      "        2         20\n",
      "B       1         30\n",
      "        2         40\n",
      "dtype: int64\n",
      "\n",
      "Indexing and slicing:\n",
      "Value at index ('A', 2): 20\n",
      "Slicing using outer index 'A':\n",
      "Number\n",
      "1    10\n",
      "2    20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a MultiIndex using .from_tuples()\n",
    "index_tuples = [('A', 1), ('A', 2), ('B', 1), ('B', 2)]\n",
    "multi_index = pd.MultiIndex.from_tuples(index_tuples, names=['Letter', 'Number'])\n",
    "\n",
    "# Create a Series with the MultiIndex\n",
    "data = [10, 20, 30, 40]\n",
    "series = pd.Series(data, index=multi_index)\n",
    "\n",
    "# Display the original Series\n",
    "print(\"Original Series:\")\n",
    "print(series)\n",
    "\n",
    "# Create a new MultiIndex with additional levels using .reindex()\n",
    "new_index = [('A', 1, 'X'), ('A', 1, 'Y'), ('B', 2, 'X'), ('C', 1, 'Y')]\n",
    "new_multi_index = pd.MultiIndex.from_tuples(new_index, names=['Letter', 'Number', 'Subgroup'])\n",
    "reindexed_series = series.reindex(new_multi_index)\n",
    "\n",
    "# Display the reindexed Series\n",
    "print(\"\\nReindexed Series:\")\n",
    "print(reindexed_series)\n",
    "\n",
    "# Unstack the Series to convert it into a DataFrame\n",
    "unstacked_df = series.unstack()\n",
    "\n",
    "# Display the unstacked DataFrame\n",
    "print(\"\\nUnstacked DataFrame:\")\n",
    "print(unstacked_df)\n",
    "\n",
    "# Stack the DataFrame back into a Series\n",
    "stacked_series = unstacked_df.stack()\n",
    "\n",
    "# Display the stacked Series\n",
    "print(\"\\nStacked Series:\")\n",
    "print(stacked_series)\n",
    "\n",
    "# Indexing and slicing the Series with MultiIndex\n",
    "print(\"\\nIndexing and slicing:\")\n",
    "print(\"Value at index ('A', 2):\", series.loc[('A', 2)])\n",
    "print(\"Slicing using outer index 'A':\")\n",
    "print(series.loc['A'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e51248",
   "metadata": {},
   "source": [
    "## Requirement 20\n",
    "Demonstrate concatenating two Pandas series. One series contains\n",
    "automobile data. The other series contains motorcycle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9f64829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Series:\n",
      "Brand                  [Toyota, Honda, Ford, Chevrolet]\n",
      "Model                  [Camry, Civic, F-150, Silverado]\n",
      "Year                           [2018, 2019, 2020, 2021]\n",
      "Type                       [Sedan, Sedan, Truck, Truck]\n",
      "Brand                 [Honda, Yamaha, Kawasaki, Ducati]\n",
      "Model    [CBR1000RR, YZF-R1, Ninja ZX-10R, Panigale V4]\n",
      "Year                           [2019, 2020, 2021, 2022]\n",
      "Type       [Sportbike, Sportbike, Sportbike, Sportbike]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Automobile data\n",
    "automobile_data = {\n",
    "    'Brand': ['Toyota', 'Honda', 'Ford', 'Chevrolet'],\n",
    "    'Model': ['Camry', 'Civic', 'F-150', 'Silverado'],\n",
    "    'Year': [2018, 2019, 2020, 2021],\n",
    "    'Type': ['Sedan', 'Sedan', 'Truck', 'Truck']\n",
    "}\n",
    "automobile_series = pd.Series(automobile_data)\n",
    "\n",
    "# Motorcycle data\n",
    "motorcycle_data = {\n",
    "    'Brand': ['Honda', 'Yamaha', 'Kawasaki', 'Ducati'],\n",
    "    'Model': ['CBR1000RR', 'YZF-R1', 'Ninja ZX-10R', 'Panigale V4'],\n",
    "    'Year': [2019, 2020, 2021, 2022],\n",
    "    'Type': ['Sportbike', 'Sportbike', 'Sportbike', 'Sportbike']\n",
    "}\n",
    "motorcycle_series = pd.Series(motorcycle_data)\n",
    "\n",
    "# Concatenate the two series\n",
    "concatenated_series = pd.concat([automobile_series, motorcycle_series])\n",
    "\n",
    "# Display the concatenated series\n",
    "print(\"Concatenated Series:\")\n",
    "print(concatenated_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52732aa4",
   "metadata": {},
   "source": [
    "## Requirement 21\n",
    "Demonstrate concatenating two Pandas dataframe using the .concat()\n",
    "method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e227ab39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated DataFrame:\n",
      "       Brand         Model  Year       Type\n",
      "0     Toyota         Camry  2018      Sedan\n",
      "1      Honda         Civic  2019      Sedan\n",
      "2       Ford         F-150  2020      Truck\n",
      "3  Chevrolet     Silverado  2021      Truck\n",
      "4      Honda     CBR1000RR  2019  Sportbike\n",
      "5     Yamaha        YZF-R1  2020  Sportbike\n",
      "6   Kawasaki  Ninja ZX-10R  2021  Sportbike\n",
      "7     Ducati   Panigale V4  2022  Sportbike\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# First DataFrame with automobile data\n",
    "automobile_data1 = {\n",
    "    'Brand': ['Toyota', 'Honda', 'Ford', 'Chevrolet'],\n",
    "    'Model': ['Camry', 'Civic', 'F-150', 'Silverado'],\n",
    "    'Year': [2018, 2019, 2020, 2021],\n",
    "    'Type': ['Sedan', 'Sedan', 'Truck', 'Truck']\n",
    "}\n",
    "df1 = pd.DataFrame(automobile_data1)\n",
    "\n",
    "# Second DataFrame with motorcycle data\n",
    "motorcycle_data2 = {\n",
    "    'Brand': ['Honda', 'Yamaha', 'Kawasaki', 'Ducati'],\n",
    "    'Model': ['CBR1000RR', 'YZF-R1', 'Ninja ZX-10R', 'Panigale V4'],\n",
    "    'Year': [2019, 2020, 2021, 2022],\n",
    "    'Type': ['Sportbike', 'Sportbike', 'Sportbike', 'Sportbike']\n",
    "}\n",
    "df2 = pd.DataFrame(motorcycle_data2)\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "concatenated_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "print(\"Concatenated DataFrame:\")\n",
    "print(concatenated_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9344e669",
   "metadata": {},
   "source": [
    "## Requirement 22\n",
    "Using Pandas dataframes, demonstrate the following joins:\n",
    "* one-to-one\n",
    "* many-to-one\n",
    "* many-to-many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82c74b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-to-one join:\n",
      "   employee_id     name   department\n",
      "0            1    Alice           HR\n",
      "1            2      Bob  Engineering\n",
      "2            3  Charlie    Marketing\n",
      "3            4    David      Finance\n",
      "\n",
      "Many-to-one join:\n",
      "    department  manager  employee_id     name\n",
      "0           HR    Alice            1    Alice\n",
      "1  Engineering      Bob            2      Bob\n",
      "2    Marketing  Charlie            3  Charlie\n",
      "3      Finance    David            4    David\n",
      "\n",
      "Many-to-many join:\n",
      "   employee_id    task    project\n",
      "0            1  Task A  Project X\n",
      "1            2  Task B  Project Y\n",
      "2            2  Task B  Project Z\n",
      "3            3  Task C  Project X\n",
      "4            3  Task C  Project Y\n",
      "5            4  Task D  Project Z\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# One-to-one join\n",
    "# Create the left DataFrame\n",
    "left_df = pd.DataFrame({\n",
    "    'employee_id': [1, 2, 3, 4],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David']\n",
    "})\n",
    "# Create the right DataFrame\n",
    "right_df = pd.DataFrame({\n",
    "    'employee_id': [1, 2, 3, 4],\n",
    "    'department': ['HR', 'Engineering', 'Marketing', 'Finance']\n",
    "})\n",
    "# Perform the one-to-one join\n",
    "one_to_one_join = pd.merge(left_df, right_df, on='employee_id')\n",
    "\n",
    "# Many-to-one join\n",
    "# Create the left DataFrame\n",
    "left_df = pd.DataFrame({\n",
    "    'department': ['HR', 'Engineering', 'Marketing', 'Finance'],\n",
    "    'manager': ['Alice', 'Bob', 'Charlie', 'David']\n",
    "})\n",
    "# Create the right DataFrame\n",
    "right_df = pd.DataFrame({\n",
    "    'employee_id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve']\n",
    "})\n",
    "# Perform the many-to-one join\n",
    "many_to_one_join = pd.merge(left_df, right_df, left_on='manager', right_on='name')\n",
    "\n",
    "# Many-to-many join\n",
    "# Create the left DataFrame\n",
    "left_df = pd.DataFrame({\n",
    "    'employee_id': [1, 2, 3, 4],\n",
    "    'task': ['Task A', 'Task B', 'Task C', 'Task D']\n",
    "})\n",
    "# Create the right DataFrame\n",
    "right_df = pd.DataFrame({\n",
    "    'employee_id': [1, 2, 2, 3, 3, 4],\n",
    "    'project': ['Project X', 'Project Y', 'Project Z', 'Project X', 'Project Y', 'Project Z']\n",
    "})\n",
    "# Perform the many-to-many join\n",
    "many_to_many_join = pd.merge(left_df, right_df, on='employee_id')\n",
    "\n",
    "# Display the results\n",
    "print(\"One-to-one join:\")\n",
    "print(one_to_one_join)\n",
    "print(\"\\nMany-to-one join:\")\n",
    "print(many_to_one_join)\n",
    "print(\"\\nMany-to-many join:\")\n",
    "print(many_to_many_join)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b023f9",
   "metadata": {},
   "source": [
    "## Requirement 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e55a14",
   "metadata": {},
   "source": [
    "Using Pandas dataframes, demonstrate merge with the following\n",
    "keywords:\n",
    "* on\n",
    "* left_on and right_on\n",
    "* left_index and right_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5971e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge using 'on':\n",
      "   employee_id     name   department  salary\n",
      "0            1    Alice           HR   50000\n",
      "1            2      Bob  Engineering   60000\n",
      "2            3  Charlie    Marketing   70000\n",
      "\n",
      "Merge using 'left_on' and 'right_on':\n",
      "   employee_id     name   department  salary\n",
      "0            1    Alice           HR   50000\n",
      "1            2      Bob  Engineering   60000\n",
      "2            3  Charlie    Marketing   70000\n",
      "\n",
      "Merge using 'left_index' and 'right_index':\n",
      "                name   department  salary\n",
      "employee_id                              \n",
      "1              Alice           HR   50000\n",
      "2                Bob  Engineering   60000\n",
      "3            Charlie    Marketing   70000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "left_data = {\n",
    "    'employee_id': [1, 2, 3],\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'department': ['HR', 'Engineering', 'Marketing']\n",
    "}\n",
    "\n",
    "right_data = {\n",
    "    'employee_id': [1, 2, 3],\n",
    "    'salary': [50000, 60000, 70000]\n",
    "}\n",
    "\n",
    "# Create DataFrames\n",
    "left_df = pd.DataFrame(left_data)\n",
    "right_df = pd.DataFrame(right_data)\n",
    "\n",
    "# Merge using 'on'\n",
    "on_merge = pd.merge(left_df, right_df, on='employee_id')\n",
    "\n",
    "# Merge using 'left_on' and 'right_on'\n",
    "left_on_right_on_merge = pd.merge(left_df, right_df, left_on='employee_id', right_on='employee_id')\n",
    "\n",
    "# Set index for DataFrames\n",
    "left_df.set_index('employee_id', inplace=True)\n",
    "right_df.set_index('employee_id', inplace=True)\n",
    "\n",
    "# Merge using 'left_index' and 'right_index'\n",
    "index_merge = pd.merge(left_df, right_df, left_index=True, right_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(\"Merge using 'on':\")\n",
    "print(on_merge)\n",
    "\n",
    "print(\"\\nMerge using 'left_on' and 'right_on':\")\n",
    "print(left_on_right_on_merge)\n",
    "\n",
    "print(\"\\nMerge using 'left_index' and 'right_index':\")\n",
    "print(index_merge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb618dd",
   "metadata": {},
   "source": [
    "## Requirement 24\n",
    "Use markdown to include a statement at the end of assignment-11.ipynb\n",
    "explaining your experiences with Assignment 11. Make this authentic\n",
    "(minimum of 2-3 sentences).\n",
    "\n",
    "\n",
    "Working on Assignment 11 was an insightful experience. Exploring various Pandas operations and techniques helped me deepen my understanding of data manipulation in Python. I particularly enjoyed experimenting with different join types and merging strategies, which broadened my knowledge of relational database concepts in the context of data analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df94992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
